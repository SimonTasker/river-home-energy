from paho.mqtt import client as mqtt_client
import pickle
import time

# Using a pickled data file (generated by influx_retreive_mqtt_to_json.py)
# Re-publish back to the MQTT broker, to allow for testing on historic data

# Pickled data
file_path = "/Users/simontasker/Documents/MSc Software Engineering/Dissertation/Source/river-home-energy/tools/output_kettle_30d.pkl"
# MQTT settings
broker = "raspberrypi.local"
port = 1883
topic = "test/Tasmota_Kettle_Replay/SENSOR"

# Connect to the MQTT broker
def connect_mqtt():
    def on_connect(client, userdata, flags, rc):
        if rc == 0:
            print("Connected to MQTT Broker!")
        else:
            print("Failed to connect, return code %d\n", rc)

    client = mqtt_client.Client()
    client.on_connect = on_connect
    client.connect(broker, port)
    return client

# Publish data to MQTT broker, using given client
def publish(client, msg):
    client.publish(topic, msg)

# Load the pickled data from the file
with open(file_path, "rb") as file:
    pickled_data = file.read()

def run():
    # Connect to MQTT broker
    client = connect_mqtt()
    client.loop_start()
    # Unpickle the data
    output = pickle.loads(pickled_data)

    # Publish all data
    for val in output:
        # N.B. without sleep, will publish as fast as possible
        time.sleep(0.00115741) # Publish at rate of 1 day every 10 seconds
        # string quotes need to be " as opposed to '
        publish(client, str(val).replace("'", '"'))

if __name__ == '__main__':
    run()